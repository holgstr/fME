<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="fmeffects">
<title>Why FMEs? • fmeffects</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.11/clipboard.min.js" integrity="sha512-7O5pXpc0oCRrxk8RUfDYFgn0nO1t+jLuIOQdOMRp4APB7uZ4vSjspzp5y6YDtDs4VzUSTbWzBFZ/LKJhnyFOKw==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Why FMEs?">
<meta property="og:description" content="fmeffects">
<meta property="og:image" content="https://holgstr.github.io/fmeffects/logo.png">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light" data-bs-theme="light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">fmeffects</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.1.3</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../articles/fmeffects.html">Get started</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/fme_theory.html">Why FMEs?</a>
  </div>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">Changelog</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/holgstr/fmeffects/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Why FMEs?</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/holgstr/fmeffects/blob/HEAD/vignettes/fme_theory.Rmd" class="external-link"><code>vignettes/fme_theory.Rmd</code></a></small>
      <div class="d-none name"><code>fme_theory.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="intuition">Intuition<a class="anchor" aria-label="anchor" href="#intuition"></a>
</h2>
<p>Forward Marginal Effects (FMEs) are probably the most intuitive way
to interpret feature effects in supervised ML models. Remember how we
interpret the beta coefficient of a numerical feature in a linear
regression model <span class="math inline">\(\mathbb{E}[Y] = \beta_{0} +
\beta_{1}x_{1} + \ldots + \beta_{p}x_{p}\)</span>:<br></p>
<p><strong><em>If</em></strong> <span class="math inline">\(x_{j}\)</span> <strong><em>increases by one unit,
the predicted target variable increases by</em></strong> <span class="math inline">\(\beta_{j}\)</span>.<br></p>
<p>FMEs make use of this instinct and apply it straightforwardly to any
model.<br>
In short, FMEs are the answer to the following question:<br></p>
<p><strong><em>What is the change in the predicted target variable if we
change the value of the feature by</em></strong> <span class="math inline">\(h\)</span> <strong><em>units?</em></strong><br></p>
<p>A few examples: <em>What is the change in predicted blood pressure if
a patients’ weight increases by</em> <span class="math inline">\(h\)</span> <em>= 1 kg? What is the change in
predicted life satisfaction if a person’s monthly income increases
by</em> <span class="math inline">\(h\)</span> <em>= 1,000 US
dollars?</em> Per default, <span class="math inline">\(h\)</span> will
be 1. However, <span class="math inline">\(h\)</span> can be chosen to
match the desired scale of interpretation.</p>
<hr>
</div>
<div class="section level2">
<h2 id="compute-effects">Compute Effects<a class="anchor" aria-label="anchor" href="#compute-effects"></a>
</h2>
<p>The big advantage of FMEs is that they are very simple. The FME is
defined observation-wise, i.e., it is computed separately for each
observation in the data. Often, we are more interested in estimating a
global effect, so we do the following:<br></p>
<p><strong>1. Compute the FME for each observation in the
data</strong><br><strong>2. Compute the Average Marginal Effect (AME)</strong><br></p>
<div class="section level3">
<h3 id="numerical-features">Numerical Features<a class="anchor" aria-label="anchor" href="#numerical-features"></a>
</h3>
<div class="section level4">
<h4 id="univariate-feature-effects">Univariate Feature Effects<a class="anchor" aria-label="anchor" href="#univariate-feature-effects"></a>
</h4>
<p>For a given observation <span class="math inline">\(i\)</span> and
step size <span class="math inline">\(h_{j}\)</span>, the FME of a
single numerical feature <span class="math inline">\(x_{j}\)</span> is
computed as:<br><br><span class="math inline">\(\textrm{FME}_{\mathbf{x}^{(i)}, \, h_{j}} =
\widehat{f}(x_{1}^{(i)},\, \ldots, \, x_{j}^{(i)}+h_{j},\, \ldots, \,
x_{p}^{(i)})-\widehat{f}(\mathbf{x}^{(i)})\)</span><br></p>
<p>As can be seen from the formula, the FME is simply the difference in
predictions between the original observation <span class="math inline">\(x^{(i)}\)</span> and the changed observation <span class="math inline">\((x_{1}^{(i)},\, \ldots, \, x_{j}^{(i)}+h_{j},\,
\ldots, \, x_{p}^{(i)})\)</span>, where <span class="math inline">\(h_{j}\)</span> is added to the feature <span class="math inline">\(x_{j}\)</span>.<br></p>
</div>
<div class="section level4">
<h4 id="bivariate-feature-effects">Bivariate Feature Effects<a class="anchor" aria-label="anchor" href="#bivariate-feature-effects"></a>
</h4>
<p>This is just the extension of the univariate FME to two features
<span class="math inline">\(x_{j}, x_{k}\)</span> that are affected
simultaneously by a step. Therefore, the step size becomes a vector
<span class="math inline">\(\mathbf{h} = (h_{j}, h_{k})\)</span>, where
<span class="math inline">\(h_{j}\)</span> denotes the change in <span class="math inline">\(x_{j}\)</span> and <span class="math inline">\(h_{k}\)</span> the change in <span class="math inline">\(x_{k}\)</span>:<br><br><span class="math inline">\(\textrm{FME}_{\mathbf{x}^{(i)}, \,
\mathbf{h}} = \widehat{f}(x_{1}^{(i)},\, \ldots, \, x_{j}^{(i)}+h_{j},\,
\ldots, \, x_{k}^{(i)}+h_{k}, \, \ldots,
x_{p}^{(i)})-\widehat{f}(\mathbf{x}^{(i)})\)</span><br></p>
</div>
</div>
<div class="section level3">
<h3 id="categorical-features">Categorical Features<a class="anchor" aria-label="anchor" href="#categorical-features"></a>
</h3>
<p>Equivalent to the step size <span class="math inline">\(h_{j}\)</span> of a numerical feature, we select
the category of interest <span class="math inline">\(c_{h}\)</span> for
a categorical feature <span class="math inline">\(x_{j}\)</span>. For a
given observation <span class="math inline">\(i\)</span> and category
<span class="math inline">\(c_{h}\)</span>, the FME is:<br><br><span class="math inline">\(\textrm{FME}_{\mathbf{x}^{(i)}, \, c_{h}} =
\widehat{f}(c_{h},\,
\mathbf{x}_{-j}^{(i)})-\widehat{f}(\mathbf{x}^{(i)}), \, \, \, \, \, \,
\, \,x_{j} \neq c_{h}\)</span><br></p>
<p>where we simply change the categorical feature to <span class="math inline">\(c_{h}\)</span>, leave all other features <span class="math inline">\(\mathbf{x}_{-j}^{(i)}\)</span> unchanged, and
compare the predicted value of this changed observation to the predicted
value of the unchanged observation. Obviously, we can only compute this
for observations where the original category is not the category of
interest <span class="math inline">\(x_{j} \neq c_{h}\)</span>. See <a href="https://holgstr.github.io/fmeffects/articles/fmeffects.html#categorical-features">here</a>
for an example.</p>
</div>
<div class="section level3">
<h3 id="average-marginal-effects-ame">Average Marginal Effects (AME)<a class="anchor" aria-label="anchor" href="#average-marginal-effects-ame"></a>
</h3>
<p>The AME is the mean of every observation’s FME as a global estimate
for the feature effect:<br><br><span class="math inline">\(\textrm{AME} = \frac{1}{n}\sum_{i =
1}^{n}{\, \textrm{FME}_{\mathbf{x}^{(i)}, \, h_{j}}}\)</span><br></p>
<p>Therefore, the AME is the expected difference in the predicted target
variable if the feature <span class="math inline">\(x_{j}\)</span> is
changed by <span class="math inline">\(h_{j}\)</span> units. For <span class="math inline">\(h_{j}\)</span> = 1, this corresponds to the way we
interpret the coefficient <span class="math inline">\(\beta_{j}\)</span>
of a linear regression model. However, be careful: the choice of <span class="math inline">\(h_{j}\)</span> can have a strong effect on the
estimated FMEs and AME for <strong>non-linear</strong> prediction
functions, auch as random forests or gradient-boosted trees.<br></p>
<hr>
</div>
</div>
<div class="section level2">
<h2 id="why-we-need-fmes">Why we need FMEs<a class="anchor" aria-label="anchor" href="#why-we-need-fmes"></a>
</h2>
<p>Marginal effects (ME) are already a widely used concept to interpret
statistical models. <strong>However, we believe they are ill-suited to
interpret feature effects in most ML models. Here, we explain why you
should abandon MEs in favor of FMEs:</strong><br>
In most implementations (e.g., Leeper’s <a href="https://thomasleeper.com/margins/" class="external-link">margins</a> package), MEs are
computed as numerical approximation of the partial derivative of the
prediction function w.r.t. the feature <span class="math inline">\(x_{j}\)</span>. In other words, they compute a
finite difference quotient, similar to this:<br><br><span class="math inline">\(\textrm{dME}_{\mathbf{x}^{(i)}, \, j} =
\cfrac{\widehat{f}(x_{1}^{(i)}, \, \ldots,\, x_{j}^{(i)}+h,\, \ldots, \,
x_{p}^{(i)})-\widehat{f}(\mathbf{x}^{(i)})}{h}\)</span><br></p>
<p>where <span class="math inline">\(h\)</span> typically is <em>very
small</em> (e.g. 10<span class="math inline">\({}^{-7}\)</span>). As is
explained <a href="https://arxiv.org/abs/2201.08837" class="external-link">here</a>, these
derivative-based MEs (dME) have a number of shortcomings:</p>
<p><strong>Number 1:</strong> The formula above computes an estimate for
the partial derivative, i.e., the tangent of the prediction function at
point <span class="math inline">\(\mathbf{x}^{(i)}\)</span>. The default
way to interpret this is to say: <em>if</em> <span class="math inline">\(x_{j}\)</span> <em>increases by one unit, the
predicted target variable can be expected to increase by</em> <span class="math inline">\(\textrm{ME}_{\mathbf{x}^{(i)}, \, j}\)</span>.
Unconsciously, we use a unit change (<span class="math inline">\(h\)</span> = 1) to interpret the computed ME even
though we computed an instantaneous rate of change. <strong>For
non-linear prediction functions, this can lead to substantial
misinterpretations.</strong> The image below illustrates this:</p>
<p><img src="figures/dme_error.png" style="width:50.0%"></p>
<p>The yellow line is the prediction function, the grey line is the
tangent at point <span class="math inline">\(x\)</span> = 0.5. If
interpreted with a unit change, the dME is subject to an error, due to
the non-linearity of the prediction function. The FME, however,
corresponds to the true change in prediction along the secant (green
line) between <span class="math inline">\(x\)</span> = 0.5 and <span class="math inline">\(x\)</span> = 1.5. This is simply by way of design
of the FME, as it describes exactly our intuition of interpreting
partial derivatives.<br></p>
<p><strong>Number 2:</strong> In general, dMEs are ill-suited to
describe models based on piecewise constant prediction functions (e.g.,
CART, random forests or gradient-boosted trees), as most observations
are located on piecewise constant parts of the prediction function where
the derivative equals zero. In contrast, FMEs allow for the choice of a
sensible step size <span class="math inline">\(h\)</span> that is large
enough to traverse a jump discontinuity, as can be seen in the example
below: At <span class="math inline">\(x\)</span> = -2.5 (green), the dME
is zero. Using the FME with <span class="math inline">\(h\)</span> = 1,
we get the red point with a different (lower) function value. Here, the
FME is negative, corresponding to what happens when <span class="math inline">\(x\)</span> = -2.5 increases by one unit.</p>
<p><img src="figures/piecewise_constant.png" style="width:48.0%"></p>
<p>In a way, the FME is the much smarter, little brother of the
dME:<br></p>
<ul>
<li>it describes the exact behavior of the prediction function</li>
<li>its design corresponds to the way we naturally want to interpret a
partial derivative</li>
<li>through the flexible choice of <span class="math inline">\(h\)</span>, it can be tailored to answer the
desired research question</li>
<li>it is conceptually simple: researchers can discuss the
interpretations because they understand how they are computed</li>
</ul>
<hr>
</div>
<div class="section level2">
<h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<p>Scholbeck, Christian A., et al. “Marginal Effects for Non-Linear
Prediction Functions.” arXiv preprint arXiv:2201.08837 (2022).</p>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Holger Löwe, Christian Scholbeck.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.9.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
